{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrator de Golos e Marcadores - SC Farense\n",
    "\n",
    "Extrai todos os golos e marcadores de TODOS os jogos do SC Farense do ZeroZero.pt\n",
    "\n",
    "**Fonte**: https://www.zerozero.pt\n",
    "\n",
    "**Saída**: JSON com estrutura:\n",
    "```json\n",
    "{\n",
    "  \"jogo_id\": \"123456\",\n",
    "  \"data\": \"2023-01-15\",\n",
    "  \"equipas\": {\"casa\": \"SC Farense\", \"fora\": \"CD Aves\"},\n",
    "  \"resultado\": {\"casa\": 2, \"fora\": 1},\n",
    "  \"golos\": [\n",
    "    {\"minuto\": \"15\", \"marcador\": \"João Silva\", \"equipa\": \"Farense\", \"assistência\": \"Carlos\"}\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classe Principal - Extrator de Golos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class GolosExtrator:\n    \"\"\"Extrai golos e marcadores de jogos do Farense no ZeroZero\"\"\"\n    \n    BASE_URL = \"https://www.zerozero.pt\"\n    FARENSE_URLS = [\n        # URLs de jogos do Farense (será populado dinamicamente)\n    ]\n    \n    def __init__(self, max_concurrent: int = 5, timeout: int = 15):\n        self.max_concurrent = max_concurrent\n        self.timeout = timeout\n        self.session = None\n        self.golos_por_jogo = []\n        self.erros = []\n        \n    async def init_session(self):\n        \"\"\"Inicializa sessão aiohttp\"\"\"\n        self.session = aiohttp.ClientSession(\n            headers={\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n                'Accept': 'text/html,application/xhtml+xml',\n                'Accept-Language': 'pt-PT,pt;q=0.9',\n            },\n            timeout=aiohttp.ClientTimeout(total=self.timeout)\n        )\n        logger.info(\"✓ Sessão HTTP inicializada\")\n    \n    async def close_session(self):\n        \"\"\"Fecha sessão aiohttp\"\"\"\n        if self.session:\n            await self.session.close()\n            logger.info(\"✓ Sessão HTTP fechada\")\n    \n    async def fetch_page(self, url: str) -> Optional[str]:\n        \"\"\"Fetch página com retry\"\"\"\n        for tentativa in range(3):\n            try:\n                async with self.session.get(url) as response:\n                    if response.status == 200:\n                        return await response.text()\n                    else:\n                        logger.warning(f\"Status {response.status}: {url}\")\n            except asyncio.TimeoutError:\n                logger.warning(f\"Timeout em {url} (tentativa {tentativa+1}/3)\")\n            except Exception as e:\n                logger.warning(f\"Erro em {url}: {e}\")\n            \n            if tentativa < 2:\n                await asyncio.sleep(2 ** tentativa)\n        \n        self.erros.append(url)\n        return None\n    \n    def extrair_golos_da_pagina(self, html: str, jogo_id: str) -> Dict:\n        \"\"\"Extrai golos de uma página de jogo\"\"\"\n        try:\n            soup = BeautifulSoup(html, 'html.parser')\n\n            # Extrair informações do jogo (equipas, resultado)\n            jogo_info = self._extrair_info_jogo(soup)\n\n            # Extrair golos - múltiplas estratégias\n            golos = []\n\n            # Estratégia 1: Procurar divs com classe 'goal' ou 'scorer'\n            goal_elements = soup.find_all(['div', 'span'], class_=re.compile('goal|golo|scorer|marcador|events?'))\n\n            if not goal_elements:\n                # Estratégia 2: Procurar na timeline/events section\n                timeline = soup.find(['div', 'section'], class_=re.compile('timeline|events|match.*events|match.*info'))\n                if timeline:\n                    goal_elements = timeline.find_all(['div', 'li', 'span'])\n\n            # Processar elementos encontrados\n            for elem in goal_elements:\n                golo = self._extrair_golo_do_elemento(elem, jogo_info)\n                if golo:\n                    golos.append(golo)\n\n            # Estratégia 3: Se ainda não encontrou, procurar por padrões de texto\n            if not golos:\n                golos = self._extrair_golos_por_regex(html, jogo_info)\n\n            return {\n                'jogo_id': jogo_id,\n                'data_extracao': datetime.now().isoformat(),\n                'jogo_info': jogo_info,\n                'golos': golos,\n                'total_golos': len(golos)\n            }\n\n        except Exception as e:\n            logger.error(f\"Erro ao processar jogo {jogo_id}: {e}\")\n            return None\n\n    def _extrair_info_jogo(self, soup) -> Dict:\n        \"\"\"Extrai informações básicas do jogo\"\"\"\n        jogo_info = {\n            'equipas': {'casa': None, 'fora': None},\n            'resultado': {'casa': None, 'fora': None},\n            'data': None\n        }\n\n        try:\n            # Procurar score/equipas\n            score_section = soup.find(['div', 'section'], class_=re.compile('score|match.*info|game.*info'))\n            if score_section:\n                # Extrair nomes das equipas\n                team_names = score_section.find_all(['h1', 'h2', 'h3', 'span', 'a'])\n                if len(team_names) >= 2:\n                    jogo_info['equipas']['casa'] = team_names[0].get_text(strip=True)\n                    jogo_info['equipas']['fora'] = team_names[-1].get_text(strip=True)\n\n                # Extrair resultado\n                score_match = re.search(r'(\\d+)\\s*[-:]\\s*(\\d+)', score_section.get_text())\n                if score_match:\n                    jogo_info['resultado']['casa'] = int(score_match.group(1))\n                    jogo_info['resultado']['fora'] = int(score_match.group(2))\n\n            # Extrair data\n            date_elem = soup.find(text=re.compile(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}'))\n            if date_elem:\n                jogo_info['data'] = str(date_elem).strip()\n\n        except Exception as e:\n            logger.debug(f\"Erro ao extrair info do jogo: {e}\")\n\n        return jogo_info\n\n    def _extrair_golo_do_elemento(self, elem, jogo_info) -> Optional[Dict]:\n        \"\"\"Extrai golo de um elemento HTML\"\"\"\n        try:\n            texto = elem.get_text(strip=True)\n\n            # Procurar padrão de minuto\n            minuto_match = re.search(r\"(\\d+)\\s*['\\+]\\s*(\\d*)\", texto)\n            if not minuto_match:\n                return None\n\n            minuto = minuto_match.group(1)\n\n            # Procurar nome do marcador (link ou texto próximo)\n            marcador = None\n            link = elem.find('a')\n            if link:\n                marcador = link.get_text(strip=True)\n            else:\n                # Tentar extrair nome após minuto\n                nome_match = re.search(r\"\\d+['\\+]\\s*(.+?)(?:\\(|,|$)\", texto)\n                if nome_match:\n                    marcador = nome_match.group(1).strip()\n\n            if not marcador or marcador.lower() in ['goal', 'golo', 'o.g.']:\n                return None\n\n            # Determinar equipa\n            equipa = self._determinar_equipa(texto, elem, jogo_info)\n\n            # Extrair assistência\n            assistencia = self._extrair_assistencia(texto)\n\n            return {\n                'minuto': minuto,\n                'marcador': marcador,\n                'equipa': equipa,\n                'assistencia': assistencia\n            }\n\n        except Exception as e:\n            logger.debug(f\"Erro ao extrair golo: {e}\")\n            return None\n\n    def _determinar_equipa(self, texto: str, elem, jogo_info: Dict) -> str:\n        \"\"\"Determina qual equipa marcou o golo\"\"\"\n        # Verificar contexto visual (classe do elemento)\n        classes = elem.get('class', [])\n\n        for cls in classes:\n            if 'home' in cls.lower() or 'casa' in cls.lower():\n                return jogo_info['equipas']['casa'] or 'Casa'\n            elif 'away' in cls.lower() or 'fora' in cls.lower():\n                return jogo_info['equipas']['fora'] or 'Fora'\n\n        # Verificar por padrões no texto (ex: OG, Autogolo)\n        if any(x in texto.lower() for x in ['og', 'autogolo', 'own goal']):\n            return 'Autogolo'\n\n        # Default (Farense ou primeira equipa)\n        return jogo_info['equipas']['casa'] or 'Farense'\n\n    def _extrair_assistencia(self, texto: str) -> Optional[str]:\n        \"\"\"Extrai nome do assistidor\"\"\"\n        # Procurar por padrões comuns: \"assist: Nome\", \"(assist: Nome)\"\n        assist_match = re.search(r'(?:assist\\.?|assist de|assist|assistência)[\\s:]*([A-ZÁÉÍÓÚà-ÿ][a-zà-ÿ]+(?:\\s+[A-ZÁÉÍÓÚà-ÿ][a-zà-ÿ]+)?)', texto, re.IGNORECASE)\n        if assist_match:\n            return assist_match.group(1).strip()\n        return None\n\n    def _extrair_golos_por_regex(self, html: str, jogo_info: Dict) -> List[Dict]:\n        \"\"\"Fallback: Extrai golos usando regex se parsing não funcionou\"\"\"\n        golos = []\n\n        # Padrão para encontrar golos: \"minuto' Nome\" ou \"minuto+tempo Nome\"\n        golo_pattern = r\"(\\d+)[\\s\\+](\\d*)\\s*['\\´]\\s*([A-ZÁÉÍÓÚà-ÿ][a-zà-ÿ]+(?:\\s+[A-ZÁÉÍÓÚà-ÿ][a-zà-ÿ]+)?)\"\n\n        matches = re.finditer(golo_pattern, html)\n        for match in matches:\n            minuto = match.group(1)\n            marcador = match.group(3).strip()\n\n            if marcador.lower() not in ['goal', 'golo', 'time', 'date', 'equipa']:\n                golos.append({\n                    'minuto': minuto,\n                    'marcador': marcador,\n                    'equipa': jogo_info['equipas']['casa'] or 'Farense',\n                    'assistencia': None\n                })\n\n        return golos\n    \n    async def processar_jogo(self, url: str, jogo_id: str, indice: int, total: int):\n        \"\"\"Processa um jogo específico\"\"\"\n        logger.info(f\"[{indice}/{total}] Processando jogo {jogo_id}...\")\n        \n        html = await self.fetch_page(url)\n        if html:\n            resultado = self.extrair_golos_da_pagina(html, jogo_id)\n            if resultado:\n                self.golos_por_jogo.append(resultado)\n                logger.info(f\"✓ Jogo {jogo_id}: {resultado['total_golos']} golos encontrados\")\n        \n        await asyncio.sleep(0.5)  # Rate limiting\n    \n    async def processar_multiplos_jogos(self, urls: List[tuple]):\n        \"\"\"Processa múltiplos jogos com concorrência\"\"\"\n        total = len(urls)\n        semaphore = asyncio.Semaphore(self.max_concurrent)\n        \n        async def bounded_task(url, jogo_id, indice):\n            async with semaphore:\n                await self.processar_jogo(url, jogo_id, indice, total)\n        \n        tasks = [\n            bounded_task(url, jogo_id, i+1)\n            for i, (url, jogo_id) in enumerate(urls)\n        ]\n        \n        await asyncio.gather(*tasks)\n    \n    def salvar_json(self, arquivo: str = \"golos_farense.json\"):\n        \"\"\"Salva golos em arquivo JSON\"\"\"\n        with open(arquivo, 'w', encoding='utf-8') as f:\n            json.dump(self.golos_por_jogo, f, ensure_ascii=False, indent=2)\n        logger.info(f\"✓ Dados salvos em {arquivo}\")\n\nprint(\"✓ Classe GolosExtrator criada (versão melhorada)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Função para Encontrar Links de Jogos do Farense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def encontrar_jogos_farense(extrator: GolosExtrator) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Encontra todos os links de jogos do Farense.\n",
    "    Retorna lista de tuplas (url, jogo_id)\n",
    "    \"\"\"\n",
    "    \n",
    "    urls_jogos = []\n",
    "    \n",
    "    # URLs base para procurar jogos do Farense\n",
    "    search_urls = [\n",
    "        \"https://www.zerozero.pt/equipa/sc-farense/jogos\",\n",
    "        \"https://www.zerozero.pt/equipa/sc-farense/jogos/\",\n",
    "    ]\n",
    "    \n",
    "    for search_url in search_urls:\n",
    "        logger.info(f\"Procurando jogos em {search_url}...\")\n",
    "        \n",
    "        html = await extrator.fetch_page(search_url)\n",
    "        if not html:\n",
    "            continue\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Procurar links de jogos\n",
    "        jogo_links = soup.find_all('a', href=re.compile(r'/jogo\\.php\\?id=\\d+|/match/\\d+'))\n",
    "        \n",
    "        for link in jogo_links:\n",
    "            href = link.get('href')\n",
    "            if href:\n",
    "                # Extrair jogo_id\n",
    "                id_match = re.search(r'id=(\\d+)|match/(\\d+)', href)\n",
    "                if id_match:\n",
    "                    jogo_id = id_match.group(1) or id_match.group(2)\n",
    "                    \n",
    "                    # Construir URL completa\n",
    "                    if href.startswith('http'):\n",
    "                        full_url = href\n",
    "                    else:\n",
    "                        full_url = f\"{extrator.BASE_URL}{href}\"\n",
    "                    \n",
    "                    urls_jogos.append((full_url, jogo_id))\n",
    "        \n",
    "        logger.info(f\"Encontrados {len(jogo_links)} links de jogos\")\n",
    "        break  # Se encontrou links, não precisa tentar outros URLs\n",
    "    \n",
    "    return urls_jogos\n",
    "\n",
    "print(\"✓ Função encontrar_jogos_farense criada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executar Extração - OPÇÃO A: URLs Manuais (Rápido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# OPÇÃO A: Usar URLs conhecidas (mais rápido para teste)\n# Exemplos de jogos do Farense no ZeroZero:\njogos_urls = [\n    # Jogo 1: Farense 2025\n    # (\"https://www.zerozero.pt/jogo.php?id=XXXXX\", \"XXXXX\"),\n    \n    # Você pode encontrar URLs de jogos do Farense em:\n    # https://www.zerozero.pt/equipa/sc-farense/\n    # https://www.zerozero.pt/equipa/sc-farense/2024-2025/\n]\n\nprint(f\"URLs preparadas: {len(jogos_urls)}\")\nif len(jogos_urls) == 0:\n    print(\"\\n📝 Como usar OPÇÃO A:\")\n    print(\"1. Visite https://www.zerozero.pt/equipa/sc-farense/\")\n    print(\"2. Clique em um jogo específico\")\n    print(\"3. Copie a URL completa (ex: https://www.zerozero.pt/jogo.php?id=12345)\")\n    print(\"4. Adicione como tupla (url, jogo_id) na lista jogos_urls acima\")\n    print(\"\\n⚠️  Ou use a OPÇÃO B abaixo para encontrar automaticamente.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Executar Extração - OPÇÃO B: Auto-descoberta (Mais Lento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "async def executar_extracao(urls_jogos: List[tuple]):\n    \"\"\"Executa a extração completa de golos do Farense\"\"\"\n    \n    if not urls_jogos:\n        print(\"\\n❌ Nenhuma URL fornecida!\")\n        print(\"\\nUse OPÇÃO A ou OPÇÃO B para preparar as URLs primeiro.\")\n        return\n    \n    extrator = GolosExtrator(max_concurrent=3, timeout=20)\n    \n    try:\n        # Inicializar sessão\n        await extrator.init_session()\n        \n        print(f\"\\n=== INICIANDO EXTRAÇÃO ===\")\n        print(f\"Total de jogos a processar: {len(urls_jogos)}\")\n        print(f\"Max concorrência: {extrator.max_concurrent}\")\n        \n        # Processar jogos\n        await extrator.processar_multiplos_jogos(urls_jogos)\n        \n        # Salvar resultados\n        print(\"\\n=== SALVANDO RESULTADOS ===\")\n        extrator.salvar_json(\"golos_farense.json\")\n        \n        # Estatísticas finais\n        print(f\"\\n=== RESUMO FINAL ===\")\n        print(f\"Jogos processados com sucesso: {len(extrator.golos_por_jogo)}\")\n        print(f\"Falhas/Erros: {len(extrator.erros)}\")\n        \n        if extrator.golos_por_jogo:\n            total_golos = sum(j['total_golos'] for j in extrator.golos_por_jogo)\n            print(f\"Total de golos encontrados: {total_golos}\")\n            print(f\"Média de golos por jogo: {total_golos / len(extrator.golos_por_jogo):.1f}\")\n    \n    except Exception as e:\n        logger.error(f\"Erro na execução: {e}\")\n        print(f\"\\n❌ Erro: {e}\")\n    \n    finally:\n        await extrator.close_session()\n\n# Executar com as URLs preparadas acima\nprint(\"Iniciando extração...\\n\")\nawait executar_extracao(jogos_urls)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Carregar dados salvos\n",
    "try:\n",
    "    with open('golos_farense.json', 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)\n",
    "    \n",
    "    print(f\"=== RESULTADOS ===\")\n",
    "    print(f\"Total de jogos: {len(dados)}\")\n",
    "    print(f\"\\nPrimeiros 3 jogos:\\n\")\n",
    "    \n",
    "    for i, jogo in enumerate(dados[:3]):\n",
    "        print(f\"Jogo {i+1}:\")\n",
    "        print(f\"  ID: {jogo['jogo_id']}\")\n",
    "        print(f\"  Golos: {jogo['total_golos']}\")\n",
    "        for golo in jogo['golos']:\n",
    "            assist = f\" (assist: {golo['assistencia']})\" if golo['assistencia'] else \"\"\n",
    "            print(f\"    - {golo['minuto']}' {golo['marcador']} ({golo['equipa']}){assist}\")\n",
    "        print()\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo golos_farense.json não encontrado. Execute a extração primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise e Estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    with open('golos_farense.json', 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    todos_golos = []\n",
    "    for jogo in dados:\n",
    "        for golo in jogo['golos']:\n",
    "            todos_golos.append({\n",
    "                'jogo_id': jogo['jogo_id'],\n",
    "                'minuto': int(golo['minuto']) if golo['minuto'].isdigit() else 0,\n",
    "                'marcador': golo['marcador'],\n",
    "                'equipa': golo['equipa'],\n",
    "                'assistencia': golo['assistencia']\n",
    "            })\n",
    "    \n",
    "    if todos_golos:\n",
    "        df = pd.DataFrame(todos_golos)\n",
    "        \n",
    "        print(\"=== ANÁLISE DE GOLOS ===\")\n",
    "        print(f\"\\nTotal de golos: {len(df)}\")\n",
    "        print(f\"Golos Farense: {len(df[df['equipa']=='Farense'])}\")\n",
    "        print(f\"Golos Adversários: {len(df[df['equipa']!='Farense'])}\")\n",
    "        \n",
    "        # Top marcadores\n",
    "        marcadores_farense = df[df['equipa']=='Farense']['marcador'].value_counts()\n",
    "        print(f\"\\n=== TOP 10 MARCADORES (FARENSE) ===\")\n",
    "        for marcador, gols in marcadores_farense.head(10).items():\n",
    "            print(f\"{marcador}: {gols} golo(s)\")\n",
    "        \n",
    "        # Distribuição por minuto\n",
    "        print(f\"\\n=== DISTRIBUIÇÃO POR MINUTO ===\")\n",
    "        print(f\"Minutos mais frequentes:\")\n",
    "        print(df['minuto'].value_counts().head(10))\n",
    "    else:\n",
    "        print(\"Nenhum golo encontrado nos dados.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro na análise: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exportar para Diferentes Formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_formatos(arquivo_json: str = 'golos_farense.json'):\n",
    "    \"\"\"Exporta dados para diferentes formatos\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
    "            dados = json.load(f)\n",
    "        \n",
    "        # Preparar dados para CSV\n",
    "        todos_golos = []\n",
    "        for jogo in dados:\n",
    "            for golo in jogo['golos']:\n",
    "                todos_golos.append({\n",
    "                    'jogo_id': jogo['jogo_id'],\n",
    "                    'data_extracao': jogo['data_extracao'],\n",
    "                    'minuto': golo['minuto'],\n",
    "                    'marcador': golo['marcador'],\n",
    "                    'equipa': golo['equipa'],\n",
    "                    'assistencia': golo['assistencia'] or ''\n",
    "                })\n",
    "        \n",
    "        # Exportar CSV\n",
    "        df = pd.DataFrame(todos_golos)\n",
    "        csv_arquivo = 'golos_farense.csv'\n",
    "        df.to_csv(csv_arquivo, index=False, encoding='utf-8')\n",
    "        print(f\"✓ Exportado para {csv_arquivo}\")\n",
    "        \n",
    "        # Exportar Excel (se disponível)\n",
    "        try:\n",
    "            excel_arquivo = 'golos_farense.xlsx'\n",
    "            df.to_excel(excel_arquivo, index=False, sheet_name='Golos')\n",
    "            print(f\"✓ Exportado para {excel_arquivo}\")\n",
    "        except ImportError:\n",
    "            print(\"⚠️  openpyxl não instalado. Pulando Excel.\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Arquivo {arquivo_json} não encontrado\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na exportação: {e}\")\n",
    "\nprint(\"✓ Função exportar_formatos criada\")\n# Descomentar para exportar\n# exportar_formatos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}