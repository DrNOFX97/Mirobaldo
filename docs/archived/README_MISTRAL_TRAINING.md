# ğŸ¯ Treino Mistral LoRA para Farense Bot

## âš¡ Quick Start (5 minutos)

```bash
# 1. Criar e ativar environment
python3.11 -m venv venv-mlx
source venv-mlx/bin/activate

# 2. Instalar dependÃªncias
pip install mlx mlx-lm numpy pandas torch transformers tqdm jupyter

# 3. Abrir o notebook
jupyter notebook mistral_lora_training.ipynb

# 4. Executar cÃ©lulas na ordem (demora 30min-2h)
# Checkpoints salvos automaticamente em /tmp/farense_llm_training/
```

## ğŸ“ Ficheiros Criados

| Ficheiro | DescriÃ§Ã£o |
|----------|-----------|
| `mistral_lora_training.ipynb` | **Notebook principal** - Execute isto! |
| `MISTRAL_LORA_SETUP.md` | Guia completo com configs e troubleshooting |
| `check_mlx_setup.py` | Script para verificar ambiente |
| `README_MISTRAL_TRAINING.md` | Este ficheiro |

## ğŸš€ Como ComeÃ§ar

### Passo 1: Verificar Ambiente
```bash
chmod +x check_mlx_setup.py
python3 check_mlx_setup.py
```

Deve retornar âœ… em todas as linhas.

### Passo 2: Preparar Environment

```bash
# Criar venv
python3.11 -m venv venv-mlx

# Ativar (sempre que voltar ao projeto)
source venv-mlx/bin/activate

# Instalar MLX
pip install mlx mlx-lm
```

### Passo 3: Abrir e Executar Notebook

```bash
jupyter notebook mistral_lora_training.ipynb
```

**Ordem de execuÃ§Ã£o:**
1. âœ… Setup e DependÃªncias (cÃ©lulas 1-3)
2. âœ… Carregamento de Dados (cÃ©lulas 4-8)
3. âœ… ConfiguraÃ§Ã£o do Modelo (cÃ©lulas 9-10)
4. âœ… **Treino** (cÃ©lulas 11-13) â³ *Demora aqui!*
5. âœ… Teste (cÃ©lula 14)
6. âœ… Export (cÃ©lulas 15-17)

### Passo 4: Testar Modelo

```bash
# Quando o notebook terminar:
python3 /tmp/farense_llm_training/inference.py "Quem foi Hassan Nader?"
```

Deve retornar JSON com resposta.

## ğŸ“Š Dados Utilizados

**Treino:** ~2,000 exemplos
- 1,755 exemplos do histÃ³rico (50_anos_00.jsonl)
- 200+ biogrÃ¡fias de jogadores (processadas)

**ValidaÃ§Ã£o:** ~200 exemplos

## âš™ï¸ Modelo Treinado

```
Nome: Mistral-7B-v0.1 + LoRA
Tamanho: 14GB (base) + 2GB (adapter)
Framework: MLX (Apple Silicon)
LoRA Rank: 16 (ajustÃ¡vel)
Output: /tmp/farense_llm_training/output/
```

## ğŸ’¾ RecuperaÃ§Ã£o de Crashes

**Se o Mac crashar durante treino:**

1. Abra o notebook novamente
2. Execute as mesmas cÃ©lulas
3. **Treino retoma do Ãºltimo checkpoint automaticamente**

Checkpoints salvos em:
```
/tmp/farense_llm_training/checkpoints/
  â”œâ”€â”€ checkpoint_epoch0_step200/
  â”œâ”€â”€ checkpoint_epoch1_step200/
  â””â”€â”€ training_state.json
```

## ğŸ”— IntegraÃ§Ã£o no Bot

Depois de treinar, integrar no Express server:

```javascript
// netlify/functions/api.js
const { spawn } = require('child_process');

async function generateWithMistralLoRA(prompt) {
  const python = spawn('python3', [
    '/tmp/farense_llm_training/inference.py',
    prompt
  ]);

  let output = '';
  return new Promise((resolve, reject) => {
    python.stdout.on('data', (data) => { output += data; });
    python.on('close', (code) => {
      if (code === 0) {
        const result = JSON.parse(output);
        resolve(result.response);
      } else {
        reject('MLX inference failed');
      }
    });
  });
}

// Usar como fallback para OpenAI
app.post('/api/chat', async (req, res) => {
  try {
    const response = await generateWithMistralLoRA(req.body.message);
    res.json({ message: response });
  } catch (error) {
    // Fallback para OpenAI
    const response = await openai.chat.completions.create({...});
    res.json({ message: response.choices[0].message.content });
  }
});
```

## â“ FAQ

### P: Quanto tempo demora o treino?
**R:** 30min (M2/M3) atÃ© 2h (M1 com 8GB). Deixe correr em background.

### P: Posso pausar e retomar?
**R:** **Sim!** Pressione `Ctrl+C` no notebook e execute novamente. Retoma do checkpoint.

### P: Posso treinar enquanto uso o bot?
**R:** Sim, mas serÃ¡ mais lento (~50%). Recomendo deixar a noite.

### P: O modelo serÃ¡ melhor que GPT-4?
**R:** NÃ£o, mas serÃ¡ muito especializado sobre Farense. Ideal para fallback.

### P: Preciso de GPU?
**R:** NÃ£o! MLX usa Apple Neural Engine (Metal). Melhor que GPU para M1/M2/M3.

### P: E se ficar sem espaÃ§o em disco?
**R:** Precisas ~50GB em `/tmp`. Apaga outros ficheiros lÃ¡.

## ğŸ“š DocumentaÃ§Ã£o Completa

Ver `MISTRAL_LORA_SETUP.md` para:
- ConfiguraÃ§Ã£o detalhada de hiperparÃ¢metros
- Troubleshooting completo
- Perfis de hardware (tempo de treino por Mac model)
- Comandos avanÃ§ados

## ğŸ¯ PrÃ³ximos Passos

1. âœ… Executar `python3 check_mlx_setup.py`
2. âœ… Criar venv e instalar MLX
3. âœ… Abrir e executar `mistral_lora_training.ipynb`
4. âœ… Testar modelo com `inference.py`
5. âœ… Integrar no bot (ver INTEGRATION_GUIDE.md)

## ğŸ†˜ Suporte

- **Erro ao importar MLX?** â†’ `pip install mlx mlx-lm`
- **Ficou preso numa cÃ©lula?** â†’ Pressione `Kernel â†’ Interrupt` no Jupyter
- **Checkpoint nÃ£o retoma?** â†’ Verifique `/tmp/farense_llm_training/checkpoints/`
- **Outro problema?** â†’ Verifique `MISTRAL_LORA_SETUP.md` na secÃ§Ã£o Troubleshooting

---

**Criado:** 27 Oct 2025
**Status:** âœ… Pronto para usar
**Ãšltima atualizaÃ§Ã£o:** Hoje

Boa sorte! ğŸš€
